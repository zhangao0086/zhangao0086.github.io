---
layout: post
title: "ARTS #226 | 海边"
date: 2025-03-22 22:39:07 +0800
categories: [ARTS]
article_type: 1
typora-root-url: ../../github.io
---

![](/assets/img/226-caption.jpg)

> 周末来海边 “上班” 了~

# Algorithm

本周选择的算法题是：[count-the-number-of-complete-components](https://leetcode.com/problems/count-the-number-of-complete-components/)。

```python
class Solution:
    def countCompleteComponents(self, n: int, edges: List[List[int]]) -> int:
        graph = defaultdict(list)
        for u, v in edges:
            graph[u].append(v)
            graph[v].append(u)

        def dfs(node, visited, component):
            visited.add(node)
            component.append(node)
            for neighbor in graph[node]:
                if neighbor not in visited:
                    dfs(neighbor, visited, component)

        def is_complete_component(nodes):
            size = len(nodes)
            # 检查每个节点是否都与其他所有节点相连
            for node in nodes:
                if len(graph[node]) != size - 1:
                    return False
            return True

        visited = set()
        count = 0
        for i in range(n):
            if i not in visited:
                component = []
                dfs(i, visited, component)
                if is_complete_component(component):
                    count += 1
        return count
```

# Review

[The Illustrated Stable Diffusion](https://jalammar.github.io/illustrated-stable-diffusion/)

这篇关于 Stable Diffusion 的介绍文章非常通俗易懂，作者从组件构成、扩散过程，到文本融入方式上剖析了 Stable Diffusion 的工作原理，文末还提供了丰富的学习资源，对想要了解 AI 图像生成技术的初学者来说，是极佳的入门材料。

# Tip

[ai-by-hand-excel](https://github.com/ImagineAILab/ai-by-hand-excel)，通过 Excel 实现并演示了 AI 与深度学习核心算法、概念，包括矩阵乘法、MLP、RNN、Transformer、ResNet 等，让初学者可以动手操作并理解 AI 的运行原理~

# Share

https://team.doubao.com/zh/tech/seedream

3.11 日字节发布了一款文生图模型，Seedream 2.0，是一款支持中英文双语的图像生成模型：

![](/assets/img/226-1.jpg)

论文中提到的技术有：

Scaled ROPE（缩放式旋转位置编码），改进了传统 2D RoPE，通过分辨率相关的缩放因子，让图像中心区域在不同分辨率下保持位置 ID 一致性，提升模型对未训练过的图像分辨率和宽高比的泛化能力，增强推理适应性：



![](/assets/img/226-2.png)

text encoder，字节通过自研文本编码器解决了传统 CLIP/T5 编码器中文理解能力薄弱以及 decoder-only LLM 文本嵌入特征分布与 CLIP/T5 差异显著导致扩散模型训练不稳定的问题。

Glyph - Aligned ByT5 字符级文本编码器，一种双重编码策略，结合 LLM 文本编码器提取语义特征和 ByT5 模型提取字形特征，然后通过 MLP 层对齐 ByT5 与 LLM 特征空间，拼接后输入 DiT 模块联合训练，以解决长文本生成中出现的重复和布局混乱问题。采用了端到端训练范式，直接通过 re-caption 模型描述文字排版特征（字体 / 颜色 / 尺寸 / 位置），降低了训练流程复杂度，提升了推理效率。

多阶段后训练优化框架，包括 Continuing Training (CT)、SFT、RLHF 和提示工程，系统性地提升模型的综合性能。这里面又有一堆东西：

- Continued Training，用于提升生成图像的美学效果。使用高质量预训练数据和人工策划的美学数据，结合 VMix 技术，VMix 为图像标注色彩、光影、纹理、构图四维美学标签，在去噪过程中注入标签作为条件，动态调整各维度损失权重，让模型学习美学特征，增强图像视觉吸引力。
- SFT & RLHF
- Prompt Engineering，优化用户 prompt 的质量，让 LLM 理解用户意图、生成更精准的 prompt，以此引导文生图模型生成高质量图像

基于指令的图像编辑模型，SeedEdit，旨在通过用户输入的文本指令，对图像进行精准编辑，同时保持图像内容与指令的一致性。比如针对人脸编辑场景，引入了基于人脸相似性测量的损失函数（结合 AdaFace 模型），计算编辑前后人脸特征的相似度，约束模型在编辑过程中保留人脸身份（ID）信息，避免编辑后人脸特征失真。

总的来说，东西很多，但缺少重点和细节，算是一款在中英双语理解、文本渲染、美学生成和多分辨率适配等方面达到了当前先进水平的模型。

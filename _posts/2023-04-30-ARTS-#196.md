---
layout: post
title: "ARTS #196 | 养了条鱼"
date: 2023-04-30 23:51:31 +0800
categories: [ARTS]
article_type: 1
typora-root-url: ../../github.io
---

![](/assets/img/196-4.jpg)

# Algorithm

本周选择的算法题是：[Find N Unique Integers Sum up to Zero](https://leetcode.com/problems/find-n-unique-integers-sum-up-to-zero/)。

```rust
impl Solution {
    pub fn sum_zero(n: i32) -> Vec<i32> {
        let mut result = vec![];
        if n % 2 == 1 {
            result.push(0);
        }
        for i in 1..=n / 2 {
            result.push(i);
            result.push(-i);
        }
        result
    }
}
```

# Review

[Prompt Engineering vs. Blind Prompting](https://mitchellh.com/writing/prompt-engineering-vs-blind-prompting)

这篇文章从 AI 系统的视角，讨论了两种不同的提示设计方法、它们各自的优缺点以及未来发展趋势，这两种方法分别是:

1. 工程化提示: 这种方法需要 AI 彻底理解用户的上下文和意图，然后提供与用户目标和上下文相关的提示，这背后需要 AI 具有理解语境和用户意图的能力
2. 盲提示: 这种方法不需要 AI 理解用户的上下文或意图，它会随机提供各种可能的下一步提示，让用户自己选择最相关的提示，虽然它不需要 AI 有很强的理解能力，但代价是提示的质量可能不高，用户体验也不好

工程化提示需要更先进的 AI 技术来理解用户和对话上下文，以便提供更高质量的体验，这也更具挑战性，难度更大。盲提示则简单易行，无门槛使用，但用户体验差一些，需要经过很多尝试（猜测）才能离目标近一点。

作者认为未来随着 AI 的进步，工程化提示可能会变得更普及和实用，拭目以待。

# Tip

[Supervisord](http://supervisord.org/) 是一个用 Python 开发的进程管理工具，可以管理和监控进程。如果你的服务要通过 nginx 反向代理，可以很容易的和自动化流程结合起来，比如：

```shell
yes | cp -rf ./supervisord.ini /etc/supervisord.d/supervisord.ini
supervisorctl reread
supervisorctl update
supervisorctl restart [SERVICE NAME]
```

# Share

## 在 llama_index 接入 Azure API 过程中的那些坑

这周用 [llama_index](https://github.com/jerryjliu/llama_index) 做了个小玩具，本来没什么好写的， 但过程实在是踩了太多坑了，

首先，确保该部署的模型都部署了。你需要有一个能管理 Azure 后台配置的账户，或者让管理员帮你检查，当遇到 `The API deployment for this resource does not exist` 错误时，要么是模型未部署，要么是 `deployment_id` 不正确：![](/assets/img/196-1.png)

其次，一定要知道 OpenAI 和 Azure 的接口存在非常多的区别，通过 OpenAI 能执行成功的动作换成 Azure 可能出现各种各样的问题，如在 embedding 过程中出现的 `Too many inputs for model None. The max number of inputs is 1.`，虽然 llama_index 提供了用于适配 Azure 的 AzureOpenAIEmbeddings，但很遗憾它的实现有 bug，只能用 `OpenAIEmbeddings(chunk_size=1)` 临时解决。

langchain 也有 bug，本来 Azure 在官网明确说了有几个参数不支持：

![](/assets/img/196-2.png)

但 langchain 头铁非要传，虽然问题在 0.0.144 解决了，结果目前最新版本的 llama_index 仍然是必须依赖 0.0.142，所以又要绕一下，比如用一个 AzureOpenAI 的子类强行 pop 掉这三个参数：

```python
from langchain.llms import AzureOpenAI
from typing import List

class NewAzureOpenAI(AzureOpenAI):
    stop: List[str] = None

    @property
    def _invocation_params(self):
        params = super()._invocation_params
        # fix InvalidRequestError: logprobs, best_of and echo parameters are not available on gpt-35-turbo model.
        params.pop('logprobs', None)
        params.pop('best_of', None)
        params.pop('echo', None)
        #params['stop'] = self.stop
        return params
```

如果你想用 embedding + gpt-3.5-turbo 搞点事情，大概率会在 refine 上遇到挫折，比如总是收到无意义的固定响应：`The original answer remains relevant and does not require refinement based on the additional context provided.`，这也是一个 bug: [Issue with Answer Refinement in gpt-3.5-turbo Chat Model within RAG Framework](https://github.com/jerryjliu/llama_index/issues/1335)，目前官方还未解决，有两个简单的方法可以绕过：

1. 用 text-davinci-003 模型代替 gpt-3.5-turbo
2. 把默认的 refine 模板改掉

还有问题排查的过程，由于将 OpenAI 切换为 Azure 后出现了太多问题，本想通过抓包的方式看看在接口层面有何不同，但网络层做了常见的证书校验，不过好在 openai 提供了 `verify_ssl_certs` 参数用于禁用校验，但实际的情况是这个参数设置了个寂寞：

![](/assets/img/196-3.png)

还有最终发布的环节，笔者还遇到了管理员休假没带电脑导致无法发布的情况，虽然跌跌撞撞最终全都解决了，但其实本不必这么费劲，特此记录一下。

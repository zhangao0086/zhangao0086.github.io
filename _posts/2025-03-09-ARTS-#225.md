---
layout: post
title: "ARTS #225 | 胡辣汤与 EliGen"
date: 2025-03-09 23:54:06 +0800
categories: [ARTS]
article_type: 1
typora-root-url: ../../github.io
---

![](/assets/img/225-caption.jpg)

> 北京一家特别棒的胡辣汤，名字叫方中山

# Algorithm

本周选择的算法题是：[Minimum Recolors to Get K Consecutive Black Blocks](https://leetcode.com/problems/minimum-recolors-to-get-k-consecutive-black-blocks/)。

```python
class Solution:
    def minimumRecolors(self, blocks: str, k: int) -> int:
        whites = blocks[:k].count('W')
        min_recolors = whites

        for i in range(k, len(blocks)):
            whites += (blocks[i] == 'W') - (blocks[i - k] == 'W')
            min_recolors = min(min_recolors, whites)

        return min_recolors
```

一个简洁的滑动窗口实现。

# Review

[The case against self-closing tags in HTML](https://jakearchibald.com/2023/against-self-closing-tags-in-html/)

作者围绕 HTML 中的自闭合标签语法  `/>` 展开了讨论，认为它是已废弃规范（XML）的残余，不应推广使用。

文章本身没有太多有效的信息，不过了解下 `/>` 语法的起源、XHTML 的兴衰也挺好。

# Tip

![](/assets/img/225-3.png)

> https://help.aliyun.com/zh/nas/user-guide/cross-mount-compatibility-faq

在阿里云 NAS 上操作还是要小心一点，如果有大量的 rename 操作会导致 ls 执行失败，从而导致依赖 ls 结果返回的后续操作都无法进行。

# Share

[EliGen: Entity-Level Controlled Image Generation with Regional Attention](https://arxiv.org/abs/2501.01097)

一个可控文生图模型，能精细控制实体位置和细节变化：

![](/assets/img/225-2.png)

传统 Transformer 中的 Cross-Attention 能用于建立不同模态或数据之间的关联，在文生图里它负责将文本语义与 latent space 动态对齐，确保生成的内容符合文本描述。但文本提示的语义仅通过全局注意力传播，难以精确定位实体，比如 “左侧第三棵树”。

Regional Attention 是 EliGen 提出的改进机制，在保持 Cross-Attention 全局对齐能力的同时，引入了空间掩码约束，实现实体级别的细粒度控制，它无需额外的参数，直接改造了扩散模型的注意力模块，能在单次生成中同时控制多个实体的位置、形状和属性，比如 “左侧红色汽车+右侧戴帽子的人”，这样就提高了单次前向传播中的全局 & 局部一致性：

![](/assets/img/225-4.png)

- Regional Attention 在扩散过程中，通过全局文本提示约束整体风格和布局
- 通过区域注意力掩码，将局部实体提示动态注入到对应区域，同时保留全局光照、阴影的一致性
- 修改局部实体时（如调整主体或颜色），模型自动同步更新周围环境（如反光、色调等），无需额外后处理

EliGen 的训练数据集是通过 Flux 和 Qwen2-VL 生成的：

1. FLUX.1-dev 生成了 500k 训练图像
2. 基于 Qwen2-VL 72B 的图像理解和 grounding 能力，对训练样本进行了 recaption，同时对图像中的实体的语义和位置信息进行了标注

如下图所示：

![](/assets/img/225-1.png)

现有的文生图像模型（Stable Diffusion、DiT）虽能生成高质量图像，但仅依赖全局文本提示难以实现**实体级别的精细控制**（如修改单个物体的形状、位置或属性）。EliGen 旨在通过引入**区域注意力机制**和**多模态实体条件**解决这一限制，实现更灵活、精确的图像生成与编辑。
